import os
import sys
import tempfile
import base64
from pathlib import Path

import streamlit as st
from PIL import Image
from pyvis.network import Network
import streamlit.components.v1 as components

sys.path.insert(0, str(Path(__file__).parent.resolve()))
import NLP_Project_Graph_Based_RAG  # noqa: E402  (import apr√®s modification du path)

st.set_page_config(
    page_title="RAG Multimodal avec Graphe de Connaissances",
    page_icon="üîç",
    layout="wide"
)

# ------------------------------------------------------------------
# 3) Style CSS optionnel
# ------------------------------------------------------------------
st.markdown("""
<style>
    .main {max-width: 1200px; padding: 2rem;}
    .title {color: #1E88E5; text-align: center; margin-bottom: 2rem;}
    .result-section {margin-top: 2rem; padding: 1.5rem; border-radius: 0.5rem; background-color: #f8f9fa;}
</style>
""", unsafe_allow_html=True)

# 4) Titre
st.title("üîç RAG Multimodal avec Graphe de Connaissances")
st.markdown("---")

# 5) Sidebar
with st.sidebar:
    st.header("Configuration")

    query_mode = st.radio("Type de requ√™te :", ["Texte", "Image"], index=0)

    if query_mode == "Texte":
        query_text = st.text_area(
            "Entrez votre requ√™te textuelle :",
            placeholder="Ex : O√π travaille Alice ?",
            height=100
        )
        uploaded_file = None
    else:
        query_text = None
        uploaded_file = st.file_uploader(
            "T√©l√©chargez une image :",
            type=["jpg", "jpeg", "png"]
        )
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="Aper√ßu", use_column_width=True)

    st.markdown("---")
    st.header("Param√®tres")

    max_depth = st.slider(
        "Profondeur max du graphe",
        min_value=1,
        max_value=3,
        value=2
    )
    top_k = st.slider(
        "Nombre de r√©sultats (top-k)",
        min_value=3,
        max_value=10,
        value=6
    )

    submit_button = st.button("Lancer la requ√™te", type="primary")

if submit_button:
    with st.spinner("Traitement en cours‚Ä¶"):
        # ----------------------------------------------------------
        # A) Requ√™te TEXT
        # ----------------------------------------------------------
        if query_mode == "Texte" and query_text:
            answer, subgraph = backend.search_from_txt_with_rag_context(
                query_text,
                max_graph_depth=max_depth,
                num_top_results=top_k
            )
        # ----------------------------------------------------------
        # B) Requ√™te IMAGE
        # ----------------------------------------------------------
        elif query_mode == "Image" and uploaded_file is not None:
            # On enregistre l‚Äôimage dans le dossier attendu par le backend
            save_dir = Path("user_image_search")
            save_dir.mkdir(exist_ok=True)
            img_path = save_dir / uploaded_file.name
            Image.open(uploaded_file).save(img_path)
            answer, subgraph = backend.search_from_img_with_rag_context(
                str(img_path),
                max_graph_depth=max_depth,
                num_top_results=top_k
            )
        else:
            st.warning("Veuillez saisir une question ou s√©lectionner une image.")
            st.stop()

    st.success("Requ√™te trait√©e avec succ√®s !")

    # ---- R√©ponse textuelle ------------------------------------------
    with st.expander("üìù R√©ponse g√©n√©r√©e", expanded=True):
        st.write(answer)

    # ---- Visualisation graphe ---------------------------------------
    st.markdown("### üï∏Ô∏è Contexte du graphe (sous-graphe)")
    if not subgraph:
        st.info("Aucun sous-graphe trouv√©.")
    else:
        # Construction d‚Äôun graphe PyVis √† partir du r√©sultat Neo4j
        net = Network(
            height="600px",
            width="100%",
            bgcolor="#ffffff",
            font_color="black",
            directed=True
        )

        nodes, edges = set(), set()

        for record in subgraph:
            # record["a"] est le n≈ìud source
            # record["r"] est une *liste* de relations
            for rel in record.get("r", []):
                start = rel.start_node
                end = rel.end_node

                # Ajout des n≈ìuds (id, label, properties)
                nodes.add((
                    start.element_id,
                    list(start.labels)[0] if start.labels else "Node",
                    dict(start)
                ))
                nodes.add((
                    end.element_id,
                    list(end.labels)[0] if end.labels else "Node",
                    dict(end)
                ))

                # Ajout de l‚Äôar√™te
                edges.add((
                    start.element_id,
                    end.element_id,
                    rel.type
                ))

        # Ajout dans PyVis
        for (n_id, label, props) in nodes:
            net.add_node(n_id, label=label, title=str(props), size=25)

        for (src, dst, typ) in edges:
            net.add_edge(src, dst, label=typ)

        # Export HTML temporaire + affichage
        with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as tmp:
            net.save_graph(tmp.name)
            with open(tmp.name, "r", encoding="utf-8") as f:
                components.html(f.read(), height=620)
            os.unlink(tmp.name)

with st.expander("‚ùì Comment utiliser cette application"):
    st.markdown("""
    1. S√©lectionnez **Texte** ou **Image** dans la barre lat√©rale  
    2. R√©digez votre question ou t√©l√©versez une image  
    3. Ajustez profondeur et top-k si besoin  
    4. Lancez la requ√™te et explorez la r√©ponse & le graphe !
    """)
# footer 
st.markdown("---")
st.markdown("¬© 2025 ‚Äì RAG Multimodal avec Graphe de Connaissances")